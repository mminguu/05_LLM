{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8483bb",
   "metadata": {},
   "source": [
    "\n",
    "### ğŸŒ¿ 1. Seq2Seqë€?\n",
    "\n",
    "#### ğŸ“Œ ì •ì˜\n",
    "ì…ë ¥ ì‹œí€€ìŠ¤(ë¬¸ì¥)ë¥¼ ë°›ì•„ **ì¶œë ¥ ì‹œí€€ìŠ¤(ìƒˆ ë¬¸ì¥)** ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸ êµ¬ì¡°.\n",
    "\n",
    "- ì˜ì–´ ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­  \n",
    "- ì§ˆë¬¸ â†’ ë‹µë³€ ìƒì„±  \n",
    "- ê¸´ ë¬¸ì¥ â†’ ìš”ì•½ë¬¸ ìƒì„±  \n",
    "\n",
    "ìì—°ì–´ ìƒì„± ì‘ì—…ì—ì„œ ê°€ì¥ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë”¥ëŸ¬ë‹ êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ“Œ ì™œ ì¤‘ìš”í•œê°€?\n",
    "ìì—°ì–´ëŠ” **ì•Â·ë’¤ ë¬¸ë§¥ì— í¬ê²Œ ì˜ì¡´**í•©ë‹ˆë‹¤.  \n",
    "í•˜ì§€ë§Œ ì „í†µì ì¸ ë¶„ë¥˜ ëª¨ë¸ì´ë‚˜ ê³ ì • ë²¡í„° ê¸°ë°˜ ëª¨ë¸ì€ ì´ ë¬¸ë§¥ íë¦„ì„ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë˜ì„œ ë“±ì¥í•œ ê²ƒì´ **Seq2Seq ëª¨ë¸**  \n",
    "â†’ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ì½ê³ , ê·¸ ì˜ë¯¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì‹œí€€ìŠ¤ë¥¼ **ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±**í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ 2. Seq2Seqê°€ í•„ìš”í•œ ì´ìœ \n",
    "\n",
    "| ë¬¸ì œì  | ì„¤ëª… |\n",
    "|-------|------|\n",
    "| **ì…ë ¥/ì¶œë ¥ ê¸¸ì´ê°€ ì„œë¡œ ë‹¤ë¦„** | ë²ˆì—­: \"I love you\" â†’ \"ë‚˜ëŠ” ë„ˆë¥¼ ì‚¬ë‘í•´\" (ê¸¸ì´ê°€ ë‹¤ë¦„) |\n",
    "| **í† í° ê°„ ë¬¸ë§¥ ì˜ì¡´ì„± ë¬´ì‹œ** | ë‹¨ìˆœ ëª¨ë¸ì€ ì•ë’¤ ë‹¨ì–´ ì˜í–¥ ë°˜ì˜ì´ ì–´ë µë‹¤ |\n",
    "| **ìˆœì„œ ì •ë³´ ì†ì‹¤** | ê³ ì • í”¼ì²˜ ë²¡í„°ëŠ” ë¬¸ì¥ íë¦„ì„ ë‹´ê¸° ì–´ë µë‹¤ |\n",
    "| **ìƒì„± ë¬¸ì œì— ë¶€ì í•©** | ë¶„ë¥˜ ëª¨ë¸ì€ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ìƒì„±í•˜ëŠ” ì‘ì—…ì— ë§ì§€ ì•ŠìŒ |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  3. Seq2Seq ë™ì‘ ì›ë¦¬\n",
    "\n",
    "#### â‘  **Encoder â€” ì…ë ¥ ë¬¸ì¥ ì½ê³  ìš”ì•½**\n",
    "- LSTM/GRUê°€ ì…ë ¥ ë¬¸ì¥ì˜ í† í°ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬  \n",
    "- ë§ˆì§€ë§‰ Hidden State ë‹¨ê³„ì— ë¬¸ì¥ ì „ì²´ ì˜ë¯¸(ìš”ì•½ ì •ë³´) ì €ì¥\n",
    "\n",
    "#### â‘¡ **Context Vector â€” ë¬¸ì¥ì˜ ìš”ì•½ë³¸**\n",
    "- Encoderê°€ ë§Œë“  ë¬¸ì¥ ì˜ë¯¸ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ !! ì••ì¶• !!\n",
    "- Decoderì—ê²Œ ì „ë‹¬  \n",
    "- ë²ˆì—­ ê¸°ì¤€ìœ¼ë¡œëŠ” â€œì›ë¬¸ì„ ì™„ì „íˆ ì´í•´í•œ ìƒíƒœâ€\n",
    "\n",
    "#### â‘¢ **Decoder â€” ìƒˆë¡œìš´ ë¬¸ì¥ ìƒì„±**\n",
    "- Contextë¥¼ ì²« ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë‹¤ìŒ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ìƒì„±  \n",
    "- ì´ì „ì— ìƒì„±í•œ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ì…ë ¥ìœ¼ë¡œ ë„£ìœ¼ë©° ë¬¸ì¥ì„ ì´ì–´ê°\n",
    "\n",
    "#### â‘£ **EOS (End Of Sequence) â€” ì¢…ë£Œ ì‹ í˜¸**\n",
    "- Decoderê°€ EOS í† í°ì„ ë§Œë“¤ë©´ ë¬¸ì¥ ìƒì„± ì¢…ë£Œ  \n",
    "- â€œì—¬ê¸°ì„œ ë¬¸ì¥ì´ ëë‚¬ì–´!â€ë¼ëŠ” ì‹ í˜¸\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ 4. ì‹¤ì œ í™œìš© ì˜ˆì‹œ\n",
    "\n",
    "#### ğŸ”¸ 1) ê¸°ê³„ ë²ˆì—­ (Machine Translation)\n",
    "- ì˜ì–´ â†’ í•œêµ­ì–´  \n",
    "- í•œêµ­ì–´ â†’ ì¼ë³¸ì–´  \n",
    "â†’ ê°€ì¥ ëŒ€í‘œì ì¸ Seq2Seq í™œìš© ë¶„ì•¼\n",
    "\n",
    "#### ğŸ”¸ 2) ëŒ€í™” ì‹œìŠ¤í…œ (Chatbot / QA)\n",
    "- ì§ˆë¬¸ ì…ë ¥ â†’ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±  \n",
    "- ê³ ê°ì„¼í„° ì±—ë´‡, AI ìŠ¤í”¼ì»¤ ë“±\n",
    "\n",
    "#### ğŸ”¸ 3) ë¬¸ì„œ ìš”ì•½ (Summarization)\n",
    "- ê¸´ ë¬¸ì¥/ê¸°ì‚¬ â†’ í•µì‹¬ ìš”ì•½  \n",
    "- ë‰´ìŠ¤ ìš”ì•½, ë³´ê³ ì„œ ìë™ ìš”ì•½ ì‹œìŠ¤í…œ\n",
    "\n",
    "#### ğŸ”¸ 4) ì½”ë“œ ìë™ ìƒì„± (Code Generation)\n",
    "- \"ìˆ«ì ë¦¬ìŠ¤íŠ¸ ì •ë ¬í•˜ëŠ” ì½”ë“œ ì‘ì„±í•´ì¤˜\" â†’ ì½”ë“œ ì¶œë ¥  \n",
    "- GitHub Copilot, ChatGPT êµ¬ì¡°ì— ì‚¬ìš©ë˜ëŠ” í•µì‹¬ ì•„ì´ë””ì–´\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì ì¸ë±ì‹± ë° ì›-í•« ì¸ì½”ë”©\n",
    "# ì…ë ¥ê³¼ íƒ€ê²Ÿì˜ ê³ ìœ í•œ ë¬¸ì ìˆ˜ì§‘\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "\n",
    "# for text in input_texts:\n",
    "#     for char in text:\n",
    "#         input_characters.add(char)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# =========================\n",
    "# 1. ë¬¸ì ì§‘í•©(vocabulary) ë§Œë“¤ê¸°\n",
    "# =========================\n",
    "\n",
    "# input_texts ì•ˆì— ìˆëŠ” ëª¨ë“  ë¬¸ì¥ì—ì„œ ë¬¸ì í•˜ë‚˜í•˜ë‚˜ë¥¼ ëª¨ì•„ì„œ ì§‘í•©ìœ¼ë¡œ ë§Œë“ ë‹¤.\n",
    "# { ... } ì»´í”„ë¦¬í—¨ì…˜: ì¤‘ë³µ ì œê±° + ì§‘í•©(Set) ìƒì„±\n",
    "input_characters = {char for text in input_texts for char in text}\n",
    "\n",
    "# target_texts ì•ˆì— ìˆëŠ” ëª¨ë“  ë¬¸ì¥ì—ì„œ ë¬¸ì í•˜ë‚˜í•˜ë‚˜ë¥¼ ëª¨ì•„ì„œ ì§‘í•©ìœ¼ë¡œ ë§Œë“ ë‹¤.\n",
    "target_characters = {char for target_text in target_texts for char in target_text}\n",
    "\n",
    "# ì§‘í•©(Set)ì€ ìˆœì„œê°€ ì—†ìœ¼ë‹ˆê¹Œ, sorted()ë¡œ ì •ë ¬í•´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“ ë‹¤.\n",
    "# ì´ë ‡ê²Œ í•´ì•¼ ë‚˜ì¤‘ì— indexê°€ í•­ìƒ ì¼ê´€ë˜ê²Œ ìœ ì§€ëœë‹¤.\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "# ì¸ì½”ë”ì—ì„œ ì‚¬ìš©í•  ë¬¸ì ê°œìˆ˜ (ë¬¸ì ì‚¬ì „ í¬ê¸°)\n",
    "num_encoder_tokens = len(input_characters)\n",
    "\n",
    "# ë””ì½”ë”ì—ì„œ ì‚¬ìš©í•  ë¬¸ì ê°œìˆ˜ (ë¬¸ì ì‚¬ì „ í¬ê¸°)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "# =========================\n",
    "# 2. ì‹œí€€ìŠ¤(ë¬¸ì¥) ê¸¸ì´ ì •ë³´\n",
    "# =========================\n",
    "\n",
    "# input_texts ì¤‘ì—ì„œ ê°€ì¥ ê¸´ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ì°¾ëŠ”ë‹¤. (ì¸ì½”ë” ìµœëŒ€ ê¸¸ì´)\n",
    "max_encoder_seq_length = max(len(txt) for txt in input_texts)\n",
    "\n",
    "# target_texts ì¤‘ì—ì„œ ê°€ì¥ ê¸´ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ì°¾ëŠ”ë‹¤. (ë””ì½”ë” ìµœëŒ€ ê¸¸ì´)\n",
    "max_decoder_seq_length = max(len(txt) for txt in target_texts)\n",
    "\n",
    "# =========================\n",
    "# 3. ë¬¸ì â†” ì¸ë±ìŠ¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
    "# =========================\n",
    "\n",
    "# ë¬¸ì -> ì¸ë±ìŠ¤ : enumerateë¡œ 0ë¶€í„° ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ë¥¼ ë¶™ì¸ë‹¤.\n",
    "# ì˜ˆ: {'a': 0, 'b': 1, ...}\n",
    "input_token_index = {char: i for i, char in enumerate(input_characters)}\n",
    "target_token_index = {char: i for i, char in enumerate(target_characters)}\n",
    "\n",
    "# ì¸ë±ìŠ¤ -> ë¬¸ì : ì¶”ë¡ (inference)í•  ë•Œ ìˆ«ìë¥¼ ë‹¤ì‹œ ë¬¸ìë¡œ ë°”ê¾¸ê¸° ìœ„í•´ ì—­ë§¤í•‘ì„ ë§Œë“ ë‹¤.\n",
    "# ë”•ì…”ë„ˆë¦¬ ë’¤ì§‘ê¸° (key, value ìœ„ì¹˜ ë°”ê¾¸ê¸°)\n",
    "reverse_input_token_index = {idx: char for char, idx in input_token_index.items()}\n",
    "reverse_target_token_index = {idx: char for char, idx in target_token_index.items()}\n",
    "\n",
    "# =========================\n",
    "# 4. ì›-í•« ì¸ì½”ë”©(One-Hot Encoding)ìš© ë°°ì—´ ì¤€ë¹„\n",
    "# =========================\n",
    "\n",
    "# encoder_input_data: í˜•íƒœ = (ìƒ˜í”Œ ìˆ˜, ì¸ì½”ë” ìµœëŒ€ ê¸¸ì´, ì¸ì½”ë” ë¬¸ì ìˆ˜)\n",
    "# ì²˜ìŒì—ëŠ” ëª¨ë‘ 0ìœ¼ë¡œ ì±„ìš´ë‹¤. (ë‚˜ì¤‘ì— íŠ¹ì • ìœ„ì¹˜ë§Œ 1.0ìœ¼ë¡œ ì±„ìš´ë‹¤)\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# decoder_input_data: í˜•íƒœ = (ìƒ˜í”Œ ìˆ˜, ë””ì½”ë” ìµœëŒ€ ê¸¸ì´, ë””ì½”ë” ë¬¸ì ìˆ˜)\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# decoder_target_data: ë””ì½”ë”ê°€ í•œ ìŠ¤í… ë’¤ë¥¼ ë§ì¶”ë„ë¡ í•˜ëŠ” \"ì •ë‹µ\" ë°ì´í„°\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5. ì‹¤ì œ ì›-í•« ì¸ì½”ë”© ì±„ìš°ê¸° + Teacher Forcingìš© íƒ€ê¹ƒ ë§Œë“¤ê¸°\n",
    "# =========================\n",
    "\n",
    "# i: ìƒ˜í”Œ ì¸ë±ìŠ¤, input_text: ì…ë ¥ ë¬¸ì¥, target_text: íƒ€ê¹ƒ ë¬¸ì¥\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    # ---------- ì¸ì½”ë” ì…ë ¥ ----------\n",
    "    for t, char in enumerate(input_text):\n",
    "        # ië²ˆì§¸ ë¬¸ì¥, të²ˆì§¸ íƒ€ì„ìŠ¤í…, í•´ë‹¹ ë¬¸ì ìœ„ì¹˜ ì¸ë±ìŠ¤ë¥¼ 1.0ìœ¼ë¡œ ì„¤ì •\n",
    "        # ì¦‰, \"ì´ ìœ„ì¹˜ì—ëŠ” ì´ ë¬¸ìë‹¤\" ë¼ê³  í‘œì‹œí•˜ëŠ” ê²ƒ\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "\n",
    "    # ---------- ë””ì½”ë” ì…ë ¥ & íƒ€ê¹ƒ ----------\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_input_data: ë””ì½”ë”ê°€ \"ì…ë ¥ìœ¼ë¡œ\" ë°›ëŠ” ë¬¸ì\n",
    "        # ì˜ˆ) '\\tì•ˆë…•\\n' ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ë„£ì–´ì¤Œ\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "\n",
    "        # decoder_target_data: ë””ì½”ë”ê°€ \"ë§ì¶°ì•¼ í•  ì •ë‹µ\" (í•œ ìŠ¤í… ì•)\n",
    "        # ì˜ˆì‹œ)\n",
    "        #   ë””ì½”ë” ì…ë ¥ :   \\t ì•ˆ ë…• \\n\n",
    "        #   ë””ì½”ë” íƒ€ê¹ƒ :   ì•ˆ ë…• \\n (í•œ ì¹¸ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë°€ë¦° ê²ƒ)\n",
    "        # ê·¸ë˜ì„œ t > 0 ì¼ ë•Œ, t-1 ìœ„ì¹˜ì— í˜„ì¬ charë¥¼ ì •ë‹µìœ¼ë¡œ ë‘”ë‹¤.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "# hi  ì…ë ¥\n",
    "# \\t hello  ë””ì½”ë” ì…ë ¥\n",
    "# hello \\n  ë””ì½”ë” ì¶œë ¥ - Teacher Forcing  í•œìŠ¤í… ì•ìœ¼ë¡œ ì´ë™\n",
    "print(f'ê³ ìœ  ì…ë ¥ ë¬¸ììˆ˜ : {num_encoder_tokens}')\n",
    "print(f'ê³ ìœ  íƒ€ê²Ÿ ë¬¸ììˆ˜ : {num_decoder_tokens}')\n",
    "print(f'ìµœëŒ€ ì…ë ¥ ë¬¸ì¥ê¸¸ì´ : {max_encoder_seq_length}')\n",
    "print(f'ìµœëŒ€ íƒ€ê²Ÿ ë¬¸ì¥ê¸¸ì´ : {max_decoder_seq_length}')\n",
    "print('# ìƒ˜í”Œ, ì‹œí€€ìŠ¤ ê¸¸ì´, ë¬¸ì ì‚¬ì „ í¬ê¸°')\n",
    "print(f'encoder_input_data : {encoder_input_data.shape}')\n",
    "print(f'decoder_input_data : {decoder_input_data.shape}')\n",
    "print(f'decoder_target_data : {decoder_target_data.shape}')\n",
    "\n",
    "# =========================\n",
    "# 6. ëª¨ë¸ ì„¤ì •ì„ ìœ„í•œ ì°¨ì›(ì€ë‹‰ ìƒíƒœ í¬ê¸°)\n",
    "# =========================\n",
    "\n",
    "latent_dim = 256  # LSTM ì€ë‹‰ ìƒíƒœ í¬ê¸° (ë‚´ë¶€ ë©”ëª¨ë¦¬ í¬ê¸°, íŠ¹ì§• ë²¡í„° ì°¨ì› ìˆ˜)\n",
    "\n",
    "# =========================\n",
    "# 7. Encoder (ì¸ì½”ë”) ì •ì˜\n",
    "# =========================\n",
    "\n",
    "# ì¸ì½”ë” ì…ë ¥ í…ì„œ ì •ì˜\n",
    "# shape=(None, num_encoder_tokens)\n",
    "#  - None: íƒ€ì„ìŠ¤í… ê¸¸ì´(ë¬¸ì¥ ê¸¸ì´). ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ í—ˆìš©.\n",
    "#  - num_encoder_tokens: í•œ íƒ€ì„ìŠ¤í…ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ì›-í•« ë²¡í„° ê¸¸ì´(ë¬¸ì ìˆ˜)\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_input')\n",
    "\n",
    "# LSTM ì¸µ ì •ì˜\n",
    "# return_state=True â†’ ë§ˆì§€ë§‰ ì‹œì ì˜ hidden state(h)ì™€ cell state(c)ë¥¼ ê°™ì´ ë°˜í™˜\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "\n",
    "# encoder_outputs: ëª¨ë“  íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥ (ì—¬ê¸°ì„  ì‚¬ìš© ì•ˆ í•¨)\n",
    "# state_h: ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ hidden state\n",
    "# state_c: ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ cell state\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# ë””ì½”ë”ì— ë„˜ê²¨ì¤„ ì¸ì½”ë”ì˜ ìµœì¢… ìƒíƒœ(h, c)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# =========================\n",
    "# 8. Decoder (ë””ì½”ë”) ì •ì˜\n",
    "# =========================\n",
    "\n",
    "# ë””ì½”ë” ì…ë ¥ í…ì„œ ì •ì˜\n",
    "# shape=(None, num_decoder_tokens)\n",
    "#   - None: ë””ì½”ë” ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "#   - num_decoder_tokens: íƒ€ê²Ÿ ë¬¸ì ì‚¬ì „ í¬ê¸°\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_input')\n",
    "\n",
    "# ë””ì½”ë” LSTM ì •ì˜\n",
    "# return_sequences=True â†’ ëª¨ë“  íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥ì„ ë°˜í™˜ (ê° íƒ€ì„ìŠ¤í…ë§ˆë‹¤ softmax í•˜ê¸° ìœ„í•´)\n",
    "# return_state=True â†’ ë§ˆì§€ë§‰ ìƒíƒœë„ ê°™ì´ ë°˜í™˜ (ì¶”ë¡ ìš©ì— í•„ìš”)\n",
    "decoder_lstm = LSTM(\n",
    "    latent_dim,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    name='decoder_lstm'\n",
    ")\n",
    "\n",
    "# ë””ì½”ë” LSTM ì‹¤í–‰\n",
    "# initial_state=encoder_states â†’ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ìƒíƒœë¥¼ ë””ì½”ë”ì˜ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©\n",
    "# ì¦‰, \"ì…ë ¥ ë¬¸ì¥ì˜ ì˜ë¯¸\"ë¥¼ ë””ì½”ë”ì—ê²Œ ë„˜ê²¨ì£¼ëŠ” ì—­í• \n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# =========================\n",
    "# 9. ì¶œë ¥ì¸µ(Dense + softmax)\n",
    "# =========================\n",
    "\n",
    "# ê° íƒ€ì„ìŠ¤í…ì—ì„œ \"ë‹¤ìŒì— ì˜¬ ë¬¸ì\"ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ë½‘ëŠ” Dense ì¸µ\n",
    "# num_decoder_tokens í¬ê¸°ì˜ ë²¡í„°ë¥¼ ì¶œë ¥í•˜ê³ , softmaxë¡œ í™•ë¥  ë¶„í¬ê°€ ë¨\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "\n",
    "# ë””ì½”ë”ì˜ RNN ì¶œë ¥(decoder_outputs)ì— Dense ì¸µì„ ì”Œì›Œ ìµœì¢… ë¬¸ì í™•ë¥ ì„ ì–»ëŠ”ë‹¤.\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# =========================\n",
    "# 10. í•™ìŠµìš© ì „ì²´ ëª¨ë¸ ì •ì˜\n",
    "# =========================\n",
    "\n",
    "# ì…ë ¥: [encoder_inputs, decoder_inputs]\n",
    "# ì¶œë ¥: decoder_outputs (ê° íƒ€ì„ìŠ¤í…ë§ˆë‹¤ì˜ ë¬¸ì í™•ë¥ )\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='seq2seq_training')\n",
    "\n",
    "print(\"\\n ëª¨ë¸ êµ¬ì¡°:\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "052092d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ : Hello                --> íƒ€ê²Ÿ : \tBonjour\n",
      "\n",
      "ì…ë ¥ : How are you          --> íƒ€ê²Ÿ : \tComment allez-vous\n",
      "\n",
      "ì…ë ¥ : Good morning         --> íƒ€ê²Ÿ : \tBonjour matin\n",
      "\n",
      "ì…ë ¥ : Thank you            --> íƒ€ê²Ÿ : \tMerci\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "\n",
    "data_pairs = [\n",
    "    (\"Hello\", \"Bonjour\"),\n",
    "    (\"How are you\", \"Comment allez-vous\"),\n",
    "    (\"Good morning\", \"Bonjour matin\"),\n",
    "    (\"Thank you\", \"Merci\"),\n",
    "]\n",
    "\n",
    "# ì…ë ¥ê³¼ íƒ€ê²Ÿì„ ë¶„ë¦¬\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "for eng , fra in data_pairs:\n",
    "    input_texts.append(eng)\n",
    "    target_texts.append(f'\\t{fra}\\n')\n",
    "for i in range(len(input_texts)):\n",
    "    print(f'ì…ë ¥ : {input_texts[i]:20s} --> íƒ€ê²Ÿ : {target_texts[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a746c",
   "metadata": {},
   "source": [
    "\n",
    "ë¬¸ì ë‹¨ìœ„ ì‚¬ì „(vocabulary) ìƒì„± ë° ì •ìˆ˜ ì¸ë±ìŠ¤ ë³€í™˜\n",
    "\n",
    "ê°œë…:\n",
    "    \n",
    "ê° ë¬¸ìë¥¼ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ë§¤í•‘\n",
    "\n",
    "ì…ë ¥ê³¼ íƒ€ê²Ÿì˜ ì‚¬ì „ì€ ë³„ë„ ê´€ë¦¬\n",
    "\n",
    "ì›-í•« ì¸ì½”ë”©ìœ¼ë¡œ ì‹ ê²½ë§ ì…ë ¥ í˜•íƒœ ìƒì„±\n",
    "\n",
    "ì„¤ëª…:\n",
    "    \n",
    "input_characters: ì˜ì–´ ë¬¸ì¥ì— ë“±ì¥í•˜ëŠ” ëª¨ë“  ê³ ìœ  ë¬¸ì\n",
    "\n",
    "target_characters: í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ + íŠ¹ìˆ˜ í† í°(\\t, \\n)\n",
    "\n",
    "encoder_input_data: 3D ë°°ì—´ (ìƒ˜í”Œ, ì‹œí€€ìŠ¤ ê¸¸ì´, ë¬¸ì ì‚¬ì „ í¬ê¸°)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc51a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_characters = {char for text in input_texts for char in text}\n",
    "target_characters = {char for target_text in target_texts  for char in target_text}\n",
    "\n",
    "# ì •ë ¬í•´ì„œ ì¼ê´€ì„± í™•ë³´\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters= sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# ê°€ì¥ ê¸´ ë¬¸ì¥ ê¸¸ì´ ê³„ì‚°\n",
    "max_encoder_seq_length = max(len(txt) for txt in input_texts  )\n",
    "max_decoder_seq_length = max(len(txt) for txt in target_texts  )\n",
    "# ë¬¸ì-> ì¸ë±ìŠ¤ ë§¤í•‘\n",
    "input_token_index = { char:i for i,char in enumerate(input_characters)}\n",
    "target_token_index = { char:i for i,char in enumerate(target_characters)}\n",
    "\n",
    "# ì¸ë±ìŠ¤ -> ë¬¸ì ì—­ë§¤í•‘(ì¶”ë¡ ì‹œ ì‚¬ìš©)\n",
    "reverse_input_token_index =  { idx:char for char,idx in input_token_index.items()}\n",
    "reverse_target_token_index = { idx:char for char,idx in target_token_index.items()}\n",
    "#  encoder_input_data: 3D ë°°ì—´ (ìƒ˜í”Œ, ì‹œí€€ìŠ¤ ê¸¸ì´, ë¬¸ì ì‚¬ì „ í¬ê¸°)\n",
    "encoder_input_data = np.zeros( (len(input_texts),max_encoder_seq_length,num_encoder_tokens ),\n",
    "                            dtype='float32' )\n",
    "decoder_input_data = np.zeros( (len(input_texts),max_decoder_seq_length,num_decoder_tokens ),\n",
    "                            dtype='float32' )\n",
    "decoder_target_data = np.zeros( (len(input_texts),max_decoder_seq_length,num_decoder_tokens ),\n",
    "                            dtype='float32' )\n",
    "\n",
    "# ë¬¸ìë³„ ì›í•« ì¸ì½”ë”©\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0    \n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_input_data: ì „ì²´ íƒ€ê²Ÿ ì‹œí€€ìŠ¤ (ì‹œì‘ í† í° í¬í•¨)\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0        \n",
    "        # decoder_target_data: í•œ íƒ€ì„ìŠ¤í… ì•ì„  ì •ë‹µ (Teacher Forcingìš©)\n",
    "        # ë””ì½”ë” ì…ë ¥ \\tì•ˆë…•\n",
    "        # ë””ì½”ë” ì¶œë ¥ ì•ˆë…•\\n\n",
    "        # í•œ ìŠ¤í… ì‹œí”„íŠ¸ -  Teacher Forcing\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e54152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ëª¨ë¸ êµ¬ì¡°:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2seq_training\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"seq2seq_training\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">282,624</span> â”‚ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">285,696</span> â”‚ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_dense       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,654</span> â”‚ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     â”‚    \u001b[38;5;34m282,624\u001b[0m â”‚ encoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     â”‚    \u001b[38;5;34m285,696\u001b[0m â”‚ decoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)]             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_dense       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)  â”‚      \u001b[38;5;34m5,654\u001b[0m â”‚ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,974</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m573,974\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,974</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m573,974\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 256  # LSTM ì€ë‹‰ ì°¨ì› (ë‚´ë¶€ í‘œí˜„ í¬ê¸°)\n",
    "\n",
    "# ==================== Encoder ====================\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_input')\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# encoder_outputsëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê³ , ë‚´ë¶€ ìƒíƒœ(state_h, state_c)ë§Œ ë””ì½”ë”ë¡œ ì „ë‹¬\n",
    "# ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ LSTMì— í†µê³¼ì‹œì¼œì„œ ë§ˆì§€ë§‰ ì€ë‹‰ìƒíƒœstate_h)ì™€ ì…€ìƒíƒœ(state_c)ë¥¼ ë°›ì•„ì„œ\n",
    "# ë‘ ìƒíƒœë¥¼ ì…ë ¥ë¬¸ì¥ì˜ ì˜ë¯¸(context)ë¥¼ ì••ì¶•í•œ ë²¡í„°\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# ==================== Decoder ====================\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_input')\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "\n",
    "# ë””ì½”ë” ì´ˆê¸° ìƒíƒœë¡œ ì¸ì½”ë” ìµœì¢… ìƒíƒœ ì‚¬ìš© (ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬)\n",
    "# ì¸ì½”ë”ì˜ ìƒíƒœ(state_h , state_c)ë¥¼ ì´ˆê¸°ìƒíƒœë¡œ ë°›ì•„ì„œ ìì‹ ì˜ ì…ë ¥ decoder_inputsì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡\n",
    "# ê° ì‹œì ì˜ ì¶œë ¥ì€ Dense+Softmaxê±°ì³ì„œ ë‹¨ì–´(ë¬¸ì) í™•ë¥ ë¶„í¬\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# ê° íƒ€ì„ìŠ¤í…ì—ì„œ ë¬¸ì í™•ë¥  ë¶„í¬ ìƒì„±\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# ==================== í•™ìŠµ ëª¨ë¸ ====================\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='seq2seq_training')\n",
    "\n",
    "print(\"\\n ëª¨ë¸ êµ¬ì¡°:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f532b",
   "metadata": {},
   "source": [
    "ëª©ì : Seq2Seq ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "ê°œë…:\n",
    "\n",
    "    - categorical_crossentropy: ë‹¤ì¤‘ í´ë˜ìŠ¤(ë¬¸ì ì‚¬ì „) ì†ì‹¤\n",
    "\n",
    "    - Teacher Forcing: decoder_input_dataëŠ” ì •ë‹µ ì‹œí€€ìŠ¤ ì „ì²´ ì œê³µ\n",
    "\n",
    "    - í•™ìŠµ ëª©í‘œ: decoder_target_data (í•œ íƒ€ì„ìŠ¤í… ì•ë‹¹ê¸´ ì •ë‹µ)\n",
    "\n",
    "ì„¤ëª…:\n",
    "\n",
    "    - optimizer='rmsprop': ìˆœí™˜ì‹ ê²½ë§ì— ì•ˆì •ì ì¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜\n",
    "\n",
    "    - epochs=100: ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ ì¶©ë¶„í•œ ë°˜ë³µ í•„ìš”\n",
    "\n",
    "    - batch_size=2: ë©”ëª¨ë¦¬ íš¨ìœ¨ (ì‹¤ì œë¡œëŠ” ì „ì²´ 4ê°œ ìƒ˜í”Œ ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de633f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data,decoder_input_data],  # seq2seq\n",
    "    decoder_target_data,\n",
    "    batch_size = 2,\n",
    "    epochs = 10000,\n",
    "    # vallidation_split = 0.0,  # ë°ì´í„°ì…‹ì´ ì‘ì•„ì„œ ë¶„í•  ì•ˆí•¨\n",
    "    verbose = 0 # 0 ì¶œë ¥ì•ˆí•˜ê³  1ì€ ê°„ë‹¨í•˜ê²Œ 2 ì¢€ë” ê°„ë‹¨í•˜ê²Œ ì¶œë ¥\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0456513a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.550000011920929"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd3a8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder ì¶”ë¡  ëª¨ë¸\n",
    "encoder_model = Model(encoder_inputs,encoder_states , name='encoder_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c00697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder ì¶”ë¡  ëª¨ë¸\n",
    "# ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ\n",
    "decoder_state_input_h = Input(shape=(latent_dim,) , name='decoder_state_h')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,) , name='decoder_state_c')\n",
    "decoder_state_inputs = [decoder_state_input_h , decoder_state_input_c]\n",
    "\n",
    "# LSTM ì‹¤í–‰ (ì´ì „ìƒíƒœ + í˜„ì¬ì…ë ¥)\n",
    "decoder_outputs , state_h , state_c = decoder_lstm(decoder_inputs,initial_state=decoder_state_inputs)\n",
    "decoder_states = [state_h , state_c]\n",
    "\n",
    "# ë¬¸ì í™•ë¥  ë¶„í¬ ìƒì„±\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# ëª¨ë¸ ì¡°ë¦½\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_state_inputs,\n",
    "    [decoder_outputs] + decoder_states,\n",
    "    name='decoder_inference'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd648b9",
   "metadata": {},
   "source": [
    "ì…ë ¥ ë¬¸ì¥ì„ ë²ˆì—­í•˜ëŠ” decoding í•¨ìˆ˜ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ê°œë…:\n",
    "    - Greedy Decoding: ë§¤ ìŠ¤í… ê°€ì¥ ë†’ì€ í™•ë¥  ë¬¸ì ì„ íƒ\n",
    "\n",
    "    - ì¢…ë£Œ ì¡°ê±´: '\\n' í† í° ìƒì„± ë˜ëŠ” ìµœëŒ€ ê¸¸ì´ ë„ë‹¬\n",
    "    \n",
    "    - ìê¸°íšŒê·€ì  ìƒì„±: ì´ì „ ì˜ˆì¸¡ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ë°˜ë³µ ì‚¬ìš©\n",
    "\n",
    "ì„¤ëª…:\n",
    "\n",
    "    1. Encoderë¡œ ì…ë ¥ ë¬¸ì¥ì˜ ìƒíƒœ ë²¡í„° ì¶”ì¶œ\n",
    "\n",
    "    2. ì‹œì‘ í† í°('\\t')ìœ¼ë¡œ Decoder ì‹œì‘\n",
    "\n",
    "    3. ë°˜ë³µ: í˜„ì¬ ë¬¸ì ì˜ˆì¸¡ â†’ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "\n",
    "    4. '\\n' ë§Œë‚˜ë©´ ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98e8a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \"\"\"\n",
    "    ì…ë ¥ ì‹œí€€ìŠ¤(ì›-í•« ì¸ì½”ë”©)ë¥¼ ë°›ì•„ ë²ˆì—­ëœ ë¬¸ìì—´ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    # 1ë‹¨ê³„: Encoderë¡œ ìƒíƒœ ë²¡í„° ì¶”ì¶œ\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # 2ë‹¨ê³„: ë””ì½”ë” ì‹œì‘ í† í° ì¤€ë¹„ ('\\t')\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.0\n",
    "    \n",
    "    # 3ë‹¨ê³„: ë¬¸ìë¥¼ í•˜ë‚˜ì”© ìƒì„±\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # í˜„ì¬ ë¬¸ì ì˜ˆì¸¡ + ë‹¤ìŒ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "        \n",
    "        # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ë¬¸ì ì„ íƒ (Greedy)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_token_index[sampled_token_index]\n",
    "        \n",
    "        # ë¬¸ì ì¶”ê°€\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        # ì¢…ë£Œ ì¡°ê±´ ì²´í¬\n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "        \n",
    "        # ë‹¤ìŒ ìŠ¤í… ì¤€ë¹„: í˜„ì¬ ì˜ˆì¸¡ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        \n",
    "        # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88e2f841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ ë¬¸ì¥ : Hello\n",
      "ì •ë‹µ ë¬¸ì¥ : Bonjour\n",
      "ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ : Bonjour\n",
      "ì…ë ¥ ë¬¸ì¥ : How are you\n",
      "ì •ë‹µ ë¬¸ì¥ : Comment allez-vous\n",
      "ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ : Comment allez-vou\n",
      "ì…ë ¥ ë¬¸ì¥ : Good morning\n",
      "ì •ë‹µ ë¬¸ì¥ : Bonjour matin\n",
      "ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ : Bonjour mati\n",
      "ì…ë ¥ ë¬¸ì¥ : Thank you\n",
      "ì •ë‹µ ë¬¸ì¥ : Merci\n",
      "ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ : Merci\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(len(input_texts)):\n",
    "    # ì› í•« ì¸ì½”ë”© ì…ë ¥ ì¶”ì¶œ\n",
    "    input_seq = encoder_input_data[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    # ì‹œì‘/ì¢…ë£Œ í† í° ì œê±°\n",
    "    decoded_sentence = decoded_sentence.replace('\\t','').replace('\\n','')\n",
    "    print(f'ì…ë ¥ ë¬¸ì¥ : {input_texts[seq_index]}')\n",
    "    print(f'ì •ë‹µ ë¬¸ì¥ : {target_texts[seq_index][1:-1]}') # ì‹œì‘/ì¢…ë£Œ í† í°ì„ ì œê±°\n",
    "    print(f'ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ : {decoded_sentence}')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063877a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
